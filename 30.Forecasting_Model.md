# Forecasting Model

**1. Train Time Series Models**

-   **ARIMA (AutoRegressive Integrated Moving Average):**\
    A classical statistical model that works well with stationary time
    series data. It captures autocorrelation and trends.

-   **Prophet (by Facebook):**\
    A robust model for handling seasonality (daily, weekly, yearly),
    holidays, and missing values. Easy to tune and interpret.

-   **LSTM (Long Short-Term Memory):**\
    A deep learning model suited for sequential data. It can capture
    long-term dependencies and nonlinear relationships.

-   **XGBoost with Lag Features:**\
    A gradient boosting model where lag features (previous time steps as
    predictors) are used. Good for capturing non-linear patterns in
    tabular format.

**2. Model Comparison**

-   Evaluate models on multiple metrics to measure accuracy:

    -   **MAE (Mean Absolute Error):** Measures average magnitude of
        errors.

    -   **RMSE (Root Mean Squared Error):** Penalizes larger errors more
        heavily.

    -   **Forecast Plots:** Visual inspection of predicted vs. actual
        values to check trend and seasonality capture.

**3. Regional/Hierarchical Training**

-   If the dataset is regionalized (per-city or per-station), train
    separate models for each region.

-   This ensures the model learns localized patterns (e.g., pollution
    levels in Delhi vs. Mumbai, or temperature patterns in different
    climates).

-   Optionally, a global model can be trained with region as a feature
    for scalability.

**4. Model Selection & Saving**

-   After training and evaluation, choose the **best-performing model**
    based on validation results.

-   Save the final model using:

    -   **Pickle/Joblib** for ARIMA, XGBoost.

    -   **SavedModel / H5 format** for LSTM.

    -   **Prophet serialized objects** for Prophet.

-   The saved model is used for **inference (real-time or batch
    forecasts)**.
